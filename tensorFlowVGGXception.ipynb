{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOknVVf1jvSuBsoCQdm38ML",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simjeongho/XceptionV2/blob/main/tensorFlowVGGXception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "si4QO44IZH8U"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.applications.vgg16 import VGG16\n",
        "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, ResNet50V2, Xception"
      ],
      "metadata": {
        "id": "LRjUxfU3aCZ3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_qrSbxyaEtQ",
        "outputId": "25a8c55a-fc11-4179-9909-ee195b5fec2b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHzcfvTLaGm2",
        "outputId": "0eb413b4-a468-41cc-992a-c9fc4c5f252e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('model:', model)\n",
        "print('model output:', model.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n_SJLokaHEw",
        "outputId": "3ea53bc7-1581-454e-e720-1c112346eea4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model: <keras.engine.functional.Functional object at 0x7f3e35883c50>\n",
            "model output: KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 512), dtype=tf.float32, name=None), name='block5_pool/MaxPool:0', description=\"created by layer 'block5_pool'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "202kKarSaIa5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "끝을 수정하는 코드를 작성하여  classification의 개수를 조정할 수 있다. \n",
        "이러한 옵션은 include_top 옵션을 통해 지정할 수 있다. "
      ],
      "metadata": {
        "id": "AIJ4CGU9fO92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "# include_top=False로 기존 imagenet용 classifier 층들을 다 제거. weight는 전이학습을 위해 imagenet 학습된 weight를 초기 weight로 사용. \n",
        "#input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "#base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "\n",
        "base_model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "bm_output = base_model.output\n",
        "\n",
        "# base model의 output을 입력으로 CIFAR10용 Classification layer를 재 구성. \n",
        "x = GlobalAveragePooling2D()(bm_output)\n",
        "# x = Dropout(rate=0.5)(x)\n",
        "x = Dense(50, activation='relu', name='fc1')(x)\n",
        "# x = Dropout(rate=0.2)(x)\n",
        "output = Dense(10, activation='softmax', name='output')(x)\n",
        "\n",
        "#model = Model(inputs=input_tensor, outputs=output)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6bLC3sHaJal",
        "outputId": "1d7f795c-7065-4777-cdb3-199f65985414"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 50)                25650     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,740,848\n",
            "Trainable params: 14,740,848\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random as python_random\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n",
        "def set_random_seed(seed_value):\n",
        "    np.random.seed(seed_value)\n",
        "    python_random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)\n",
        "\n",
        "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
        "def get_preprocessed_data(images, labels, scaling=True):\n",
        "    \n",
        "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
        "    if scaling:\n",
        "        images = np.array(images/255.0, dtype=np.float32)\n",
        "    else:\n",
        "        images = np.array(images, dtype=np.float32)\n",
        "        \n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
        "def get_preprocessed_ohe(images, labels):\n",
        "    images, labels = get_preprocessed_data(images, labels, scaling=False)\n",
        "    # OHE 적용 \n",
        "    oh_labels = to_categorical(labels)\n",
        "    return images, oh_labels\n",
        "\n",
        "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
        "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
        "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
        "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
        "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
        "    \n",
        "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
        "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
        "    \n",
        "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n",
        "\n",
        "\n",
        "# random seed는 2021로 고정.\n",
        "set_random_seed(2021)\n",
        "# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
        "\n",
        "(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
        "    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
        "\n",
        "print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrQnfLjKaLer",
        "outputId": "0202a626-2559-4f44-94f9-9d7ae617abfb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "(42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    # rotation_range=20,\n",
        "    #zoom_range=(0.7, 0.9),\n",
        "    horizontal_flip=True,\n",
        "    #vertical_flip=True,\n",
        "    rescale=1/255.0\n",
        ")\n",
        "valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
        "flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "sVm7WBTMarjb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "Qcr0v0Z3ascu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "def create_model(verbose=False):\n",
        "    \n",
        "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    bm_output = base_model.output\n",
        "\n",
        "    x = GlobalAveragePooling2D()(bm_output)\n",
        "    #x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(50, activation='relu', name='fc1')(x)\n",
        "    #x = Dropout(rate=0.2)(x)\n",
        "    output = Dense(10, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    if verbose:\n",
        "        model.summary()\n",
        "        \n",
        "    return model"
      ],
      "metadata": {
        "id": "SKeWp_Pyat1O"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model = create_model(verbose=True)\n",
        "vgg_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
        "# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEyLZNw7cn-l",
        "outputId": "c2da5177-d0f9-4e86-9897-ba30f19fe294"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 50)                25650     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,740,848\n",
            "Trainable params: 14,740,848\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\n",
        "tr_data_len = tr_images.shape[0]\n",
        "val_data_len = val_images.shape[0]\n",
        "history = vgg_model.fit(flow_tr_gen, epochs=40, \n",
        "                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n",
        "                    validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n",
        "                    callbacks=[rlr_cb, ely_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWtesLtmcqNH",
        "outputId": "85b91795-3c73-4cef-cda8-73ffbd1b7a55"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "665/665 [==============================] - 36s 39ms/step - loss: 1.8967 - accuracy: 0.2506 - val_loss: 1.5240 - val_accuracy: 0.3919 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "665/665 [==============================] - 25s 38ms/step - loss: 1.3655 - accuracy: 0.4808 - val_loss: 1.1628 - val_accuracy: 0.5709 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "665/665 [==============================] - 25s 38ms/step - loss: 1.0173 - accuracy: 0.6411 - val_loss: 0.8950 - val_accuracy: 0.6885 - lr: 0.0010\n",
            "Epoch 4/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.8344 - accuracy: 0.7139 - val_loss: 0.8073 - val_accuracy: 0.7329 - lr: 0.0010\n",
            "Epoch 5/40\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.7406 - accuracy: 0.7500 - val_loss: 0.7268 - val_accuracy: 0.7548 - lr: 0.0010\n",
            "Epoch 6/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.6497 - accuracy: 0.7826 - val_loss: 0.6654 - val_accuracy: 0.7832 - lr: 0.0010\n",
            "Epoch 7/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.6013 - accuracy: 0.8024 - val_loss: 0.6450 - val_accuracy: 0.7896 - lr: 0.0010\n",
            "Epoch 8/40\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.5381 - accuracy: 0.8212 - val_loss: 0.7265 - val_accuracy: 0.7663 - lr: 0.0010\n",
            "Epoch 9/40\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.5010 - accuracy: 0.8360 - val_loss: 0.5886 - val_accuracy: 0.8107 - lr: 0.0010\n",
            "Epoch 10/40\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.4621 - accuracy: 0.8469 - val_loss: 0.5846 - val_accuracy: 0.8125 - lr: 0.0010\n",
            "Epoch 11/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.4267 - accuracy: 0.8611 - val_loss: 0.5574 - val_accuracy: 0.8273 - lr: 0.0010\n",
            "Epoch 12/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.4075 - accuracy: 0.8679 - val_loss: 0.5763 - val_accuracy: 0.8213 - lr: 0.0010\n",
            "Epoch 13/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.3718 - accuracy: 0.8797 - val_loss: 0.5926 - val_accuracy: 0.8132 - lr: 0.0010\n",
            "Epoch 14/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.3478 - accuracy: 0.8866 - val_loss: 0.6109 - val_accuracy: 0.8088 - lr: 0.0010\n",
            "Epoch 15/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.3410 - accuracy: 0.8898 - val_loss: 0.5926 - val_accuracy: 0.8224 - lr: 0.0010\n",
            "Epoch 16/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.3103 - accuracy: 0.8993\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.3103 - accuracy: 0.8993 - val_loss: 0.5638 - val_accuracy: 0.8360 - lr: 0.0010\n",
            "Epoch 17/40\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.1721 - accuracy: 0.9445 - val_loss: 0.5272 - val_accuracy: 0.8580 - lr: 2.0000e-04\n",
            "Epoch 18/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.1255 - accuracy: 0.9597 - val_loss: 0.5737 - val_accuracy: 0.8580 - lr: 2.0000e-04\n",
            "Epoch 19/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.0991 - accuracy: 0.9688 - val_loss: 0.5986 - val_accuracy: 0.8557 - lr: 2.0000e-04\n",
            "Epoch 20/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.0824 - accuracy: 0.9746 - val_loss: 0.6383 - val_accuracy: 0.8584 - lr: 2.0000e-04\n",
            "Epoch 21/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.0665 - accuracy: 0.9796 - val_loss: 0.6909 - val_accuracy: 0.8557 - lr: 2.0000e-04\n",
            "Epoch 22/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9842\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.0559 - accuracy: 0.9842 - val_loss: 0.7357 - val_accuracy: 0.8553 - lr: 2.0000e-04\n",
            "Epoch 23/40\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.0371 - accuracy: 0.9894 - val_loss: 0.7287 - val_accuracy: 0.8587 - lr: 4.0000e-05\n",
            "Epoch 24/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.0284 - accuracy: 0.9925 - val_loss: 0.7732 - val_accuracy: 0.8585 - lr: 4.0000e-05\n",
            "Epoch 25/40\n",
            "665/665 [==============================] - 26s 39ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.8361 - val_accuracy: 0.8604 - lr: 4.0000e-05\n",
            "Epoch 26/40\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.8759 - val_accuracy: 0.8584 - lr: 4.0000e-05\n",
            "Epoch 27/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9960\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "665/665 [==============================] - 26s 38ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.9569 - val_accuracy: 0.8577 - lr: 4.0000e-05\n",
            "Epoch 27: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "flow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
        "vgg_model.evaluate(flow_test_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0sa2NFFctQJ",
        "outputId": "b2ea7dbf-f79f-446c-8880-381d719375ac"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 2s 14ms/step - loss: 1.1444 - accuracy: 0.8436\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.144441843032837, 0.8435999751091003]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_history(history):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.yticks(np.arange(0, 1, 0.05))\n",
        "    plt.xticks(np.arange(0, 30, 2))\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='valid')\n",
        "    plt.legend()\n",
        "    \n",
        "show_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "g6MhHO-qcu_5",
        "outputId": "5c6c4ab3-f80a-4410-d179-a489fc86917d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7FQDOJ2Iav4G"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 image의 크기를 resize 값 만큼 증가. CIFAR10의 이미지가 32x32로 작아서 마지막 feature map의 크기가 1로 되어 모델 성능이 좋지 않음. \n",
        "# 마지막 feature map의 크기를 2로 만들기 위해 resize를 64로 하여 입력 이미지 크기를 변경. 단 메모리를 크게 소비하므로 64이상은 kernel이 다운됨. \n",
        "def get_resized_images(images, resize=64):\n",
        "    image_cnt = images.shape[0]\n",
        "    resized_images = np.zeros((images.shape[0], resize, resize, 3))\n",
        "    for i in range(image_cnt):\n",
        "        resized_image = cv2.resize(images[i], (resize, resize))\n",
        "        resized_images[i] = resized_image\n",
        "    \n",
        "    return resized_images"
      ],
      "metadata": {
        "id": "e4H9n0VsboF3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "import random as python_random\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import Xception\n",
        "\n",
        "# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n",
        "def set_random_seed(seed_value):\n",
        "    np.random.seed(seed_value)\n",
        "    python_random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)\n",
        "\n",
        "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
        "def get_preprocessed_data(images, labels, scaling=True):\n",
        "    \n",
        "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
        "    if scaling:\n",
        "        images = np.array(images/255.0, dtype=np.float32)\n",
        "    else:\n",
        "        images = np.array(images, dtype=np.float32)\n",
        "        \n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
        "def get_preprocessed_ohe(images, labels):\n",
        "    images, labels = get_preprocessed_data(images, labels, scaling=False)\n",
        "    # OHE 적용 \n",
        "    oh_labels = to_categorical(labels)\n",
        "    return images, oh_labels\n",
        "\n",
        "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
        "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
        "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
        "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
        "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
        "    \n",
        "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
        "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
        "    \n",
        "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n",
        "\n",
        "# 입력 image의 크기를 resize 값 만큼 증가. CIFAR10의 이미지가 32x32로 작아서 마지막 feature map의 크기가 1로 되어 모델 성능이 좋지 않음. \n",
        "# 마지막 feature map의 크기를 2로 만들기 위해 resize를 64로 하여 입력 이미지 크기를 변경. 단 메모리를 크게 소비하므로 64이상은 kernel이 다운됨. \n",
        "def get_resized_images(images, resize=64):\n",
        "    image_cnt = images.shape[0]\n",
        "    resized_images = np.zeros((images.shape[0], resize, resize, 3))\n",
        "    for i in range(image_cnt):\n",
        "        resized_image = cv2.resize(images[i], (resize, resize))\n",
        "        resized_images[i] = resized_image\n",
        "    \n",
        "    return resized_images\n",
        "\n",
        "def create_model(model_name='vgg16', verbose=False):\n",
        "    \n",
        "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    if model_name == 'vgg16':\n",
        "        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == 'resnet50':\n",
        "        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == 'xception':\n",
        "        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    \n",
        "    bm_output = base_model.output\n",
        "\n",
        "    x = GlobalAveragePooling2D()(bm_output)\n",
        "    if model_name != 'vgg16':\n",
        "        x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(50, activation='relu', name='fc1')(x)\n",
        "    output = Dense(10, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    model.summary()\n",
        "        \n",
        "    return model"
      ],
      "metadata": {
        "id": "zryvOGLnc_Cu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def do_cifar10_train_evaluation(image_size=IMAGE_SIZE, model_name='vgg16'):\n",
        "    set_random_seed(2021)\n",
        "    # CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
        "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "    (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
        "        get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
        "    print('데이터 세트 shape:', tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)\n",
        "    \n",
        "    # 만약 image_size가 32보다 크면 이미지 크기 재조정. \n",
        "    if image_size > 32:\n",
        "        tr_images = get_resized_images(tr_images)\n",
        "        val_images = get_resized_images(val_images)\n",
        "        test_images = get_resized_images(test_images)\n",
        "    \n",
        "    # 학습/검증/테스트용 ImageDataGenerator와 flow로 pipeline 생성. \n",
        "    train_generator = ImageDataGenerator(\n",
        "        horizontal_flip=True,\n",
        "        rescale=1/255.0\n",
        "    )\n",
        "    valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "    test_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "    flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    flow_test_gen = train_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    \n",
        "    # model_name 에 따른 모델 생성하고 모델 학습 및 검증 수행. \n",
        "    model = create_model(model_name=model_name, verbose=True)\n",
        "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
        "    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "    \n",
        "    tr_data_len = tr_images.shape[0]\n",
        "    val_data_len = val_images.shape[0]\n",
        "    history = model.fit(flow_tr_gen, epochs=40, \n",
        "                        steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n",
        "                        validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n",
        "                        callbacks=[rlr_cb, ely_cb])\n",
        "    # 테스트 데이터 세트로 모델 성능 검증 \n",
        "    evaluation_result = model.evaluate(flow_test_gen)\n",
        "    print('테스트 데이터 세트 evaluation 결과:', evaluation_result)\n",
        "    return history, evaluation_result"
      ],
      "metadata": {
        "id": "GDsBpP9_dAdp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yytHksN-a9w0",
        "outputId": "d9f47b96-3fc3-4658-eaff-0b20e11abfee"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8295"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 만약 image_size를 64로 하려면 반드시 RAM이 여유분이 충분히 있는지 확인\n",
        "history, evaluation_result = do_cifar10_train_evaluation(image_size=64, model_name='xception')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laMUur23bAqG",
        "outputId": "724f6248-d1e2-4826-e151-94005747117d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 세트 shape: (42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 15, 15, 32)   864         ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " block1_conv1_bn (BatchNormaliz  (None, 15, 15, 32)  128         ['block1_conv1[0][0]']           \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block1_conv1_act (Activation)  (None, 15, 15, 32)   0           ['block1_conv1_bn[0][0]']        \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 13, 13, 64)   18432       ['block1_conv1_act[0][0]']       \n",
            "                                                                                                  \n",
            " block1_conv2_bn (BatchNormaliz  (None, 13, 13, 64)  256         ['block1_conv2[0][0]']           \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block1_conv2_act (Activation)  (None, 13, 13, 64)   0           ['block1_conv2_bn[0][0]']        \n",
            "                                                                                                  \n",
            " block2_sepconv1 (SeparableConv  (None, 13, 13, 128)  8768       ['block1_conv2_act[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2_sepconv1_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2_sepconv2_act (Activatio  (None, 13, 13, 128)  0          ['block2_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block2_sepconv2 (SeparableConv  (None, 13, 13, 128)  17536      ['block2_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2_sepconv2_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 7, 7, 128)    8192        ['block1_conv2_act[0][0]']       \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 7, 7, 128)    0           ['block2_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 7, 7, 128)   512         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 7, 7, 128)    0           ['block2_pool[0][0]',            \n",
            "                                                                  'batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " block3_sepconv1_act (Activatio  (None, 7, 7, 128)   0           ['add[0][0]']                    \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block3_sepconv1 (SeparableConv  (None, 7, 7, 256)   33920       ['block3_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_sepconv1_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3_sepconv2_act (Activatio  (None, 7, 7, 256)   0           ['block3_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block3_sepconv2 (SeparableConv  (None, 7, 7, 256)   67840       ['block3_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_sepconv2_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 4, 4, 256)    32768       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['block3_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 4, 4, 256)    0           ['block3_pool[0][0]',            \n",
            "                                                                  'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " block4_sepconv1_act (Activatio  (None, 4, 4, 256)   0           ['add_1[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block4_sepconv1 (SeparableConv  (None, 4, 4, 728)   188672      ['block4_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4_sepconv1_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4_sepconv2_act (Activatio  (None, 4, 4, 728)   0           ['block4_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block4_sepconv2 (SeparableConv  (None, 4, 4, 728)   536536      ['block4_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4_sepconv2_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 2, 2, 728)    186368      ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 2, 2, 728)    0           ['block4_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 2, 2, 728)   2912        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 2, 2, 728)    0           ['block4_pool[0][0]',            \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " block5_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_2[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 2, 2, 728)    0           ['block5_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " block6_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_3[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 2, 2, 728)    0           ['block6_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " block7_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_4[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block7_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block7_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 2, 2, 728)    0           ['block7_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " block8_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_5[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block8_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block8_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 2, 2, 728)    0           ['block8_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " block9_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_6[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block9_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block9_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 2, 2, 728)    0           ['block9_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " block10_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_7[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block10_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block10_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 2, 2, 728)    0           ['block10_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " block11_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_8[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block11_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block11_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 2, 2, 728)    0           ['block11_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " block12_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_9[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block12_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block12_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 2, 2, 728)    0           ['block12_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " block13_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_10[0][0]']                 \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block13_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block13_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block13_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block13_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block13_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block13_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block13_sepconv2 (SeparableCon  (None, 2, 2, 1024)  752024      ['block13_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block13_sepconv2_bn (BatchNorm  (None, 2, 2, 1024)  4096        ['block13_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 1, 1, 1024)   745472      ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " block13_pool (MaxPooling2D)    (None, 1, 1, 1024)   0           ['block13_sepconv2_bn[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 1, 1, 1024)  4096        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 1, 1, 1024)   0           ['block13_pool[0][0]',           \n",
            "                                                                  'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " block14_sepconv1 (SeparableCon  (None, 1, 1, 1536)  1582080     ['add_11[0][0]']                 \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block14_sepconv1_bn (BatchNorm  (None, 1, 1, 1536)  6144        ['block14_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block14_sepconv1_act (Activati  (None, 1, 1, 1536)  0           ['block14_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block14_sepconv2 (SeparableCon  (None, 1, 1, 2048)  3159552     ['block14_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block14_sepconv2_bn (BatchNorm  (None, 1, 1, 2048)  8192        ['block14_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block14_sepconv2_act (Activati  (None, 1, 1, 2048)  0           ['block14_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3 (Gl  (None, 2048)        0           ['block14_sepconv2_act[0][0]']   \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['global_average_pooling2d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " fc1 (Dense)                    (None, 50)           102450      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 10)           510         ['fc1[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,964,440\n",
            "Trainable params: 20,909,912\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/40\n",
            "665/665 [==============================] - 81s 112ms/step - loss: 0.7784 - accuracy: 0.7453 - val_loss: 0.5033 - val_accuracy: 0.8480 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.4094 - accuracy: 0.8665 - val_loss: 0.5124 - val_accuracy: 0.8365 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.3173 - accuracy: 0.8973 - val_loss: 0.4030 - val_accuracy: 0.8736 - lr: 0.0010\n",
            "Epoch 4/40\n",
            "665/665 [==============================] - 73s 109ms/step - loss: 0.2627 - accuracy: 0.9158 - val_loss: 0.5406 - val_accuracy: 0.8372 - lr: 0.0010\n",
            "Epoch 5/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.2334 - accuracy: 0.9248 - val_loss: 0.3170 - val_accuracy: 0.8969 - lr: 0.0010\n",
            "Epoch 6/40\n",
            "665/665 [==============================] - 73s 109ms/step - loss: 0.1815 - accuracy: 0.9412 - val_loss: 0.3794 - val_accuracy: 0.8849 - lr: 0.0010\n",
            "Epoch 7/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.1571 - accuracy: 0.9478 - val_loss: 0.5175 - val_accuracy: 0.8577 - lr: 0.0010\n",
            "Epoch 8/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.1385 - accuracy: 0.9544 - val_loss: 0.4489 - val_accuracy: 0.8739 - lr: 0.0010\n",
            "Epoch 9/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.1546 - accuracy: 0.9506 - val_loss: 0.3410 - val_accuracy: 0.8976 - lr: 0.0010\n",
            "Epoch 10/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9610\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.1189 - accuracy: 0.9610 - val_loss: 0.8543 - val_accuracy: 0.8256 - lr: 0.0010\n",
            "Epoch 11/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.0712 - accuracy: 0.9773 - val_loss: 0.2477 - val_accuracy: 0.9328 - lr: 2.0000e-04\n",
            "Epoch 12/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.0327 - accuracy: 0.9898 - val_loss: 0.2586 - val_accuracy: 0.9355 - lr: 2.0000e-04\n",
            "Epoch 13/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.2805 - val_accuracy: 0.9336 - lr: 2.0000e-04\n",
            "Epoch 14/40\n",
            "665/665 [==============================] - 73s 109ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.2767 - val_accuracy: 0.9389 - lr: 2.0000e-04\n",
            "Epoch 15/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.2957 - val_accuracy: 0.9361 - lr: 2.0000e-04\n",
            "Epoch 16/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9961\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.3744 - val_accuracy: 0.9199 - lr: 2.0000e-04\n",
            "Epoch 17/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.2936 - val_accuracy: 0.9375 - lr: 4.0000e-05\n",
            "Epoch 18/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.3009 - val_accuracy: 0.9383 - lr: 4.0000e-05\n",
            "Epoch 19/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.3134 - val_accuracy: 0.9381 - lr: 4.0000e-05\n",
            "Epoch 20/40\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.3177 - val_accuracy: 0.9388 - lr: 4.0000e-05\n",
            "Epoch 21/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "665/665 [==============================] - 72s 109ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.3273 - val_accuracy: 0.9407 - lr: 4.0000e-05\n",
            "Epoch 21: early stopping\n",
            "157/157 [==============================] - 5s 29ms/step - loss: 0.3822 - accuracy: 0.9320\n",
            "테스트 데이터 세트 evaluation 결과: [0.3821974992752075, 0.9319999814033508]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('테스트 데이터세트 검증 결과:', evaluation_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0US2y0MKbBLO",
        "outputId": "6e2b3ebe-cd77-436c-fa4b-87f2907ac70e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터세트 검증 결과: [0.3821974992752075, 0.9319999814033508]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_history(history):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.yticks(np.arange(0, 1, 0.05))\n",
        "    plt.xticks(np.arange(0, 30, 2))\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='valid')\n",
        "    plt.legend()\n",
        "    \n",
        "show_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gy0Pyg8IbCQr",
        "outputId": "e717c3af-2a57-4dc7-b6ec-3786f35dd606"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}